================================================================
RepopackPy Output File
================================================================

This file was generated by RepopackPy on: 2024-10-18T17:56:04.953698

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This header section
2. Repository structure
3. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
1. This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
2. When processing this file, use the separators and "File:" markers to
  distinguish between different files in the repository.
3. Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and RepopackPy's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

For more information about RepopackPy, visit: https://github.com/abinthomasonline/repopack-py

================================================================
Repository Structure
================================================================
__pycache__/
  config.cpython-310.pyc
  main_api.cpython-310.pyc
docs/
  detailflowchat.png
  drowflowchat.jpg
  flowchat_chinese.png
  flowchat_eng.png
models/
  __pycache__/
    custom_llm.cpython-310.pyc
  custom_llm.py
modules/
  __pycache__/
    Markdown.cpython-310.pyc
    arxiv_search.cpython-310.pyc
    flowchat.cpython-310.pyc
    llm_handler.cpython-310.pyc
    mediator.cpython-310.pyc
    performance_tracker.cpython-310.pyc
    summarizer.cpython-310.pyc
    web_scraper.cpython-310.pyc
  Markdown.py
  arxiv_search.py
  flowchat.py
  llm_handler.py
  mediator.py
  performance_tracker.py
  summarizer.py
  web_scraper.py
README_English.md
README_chinese.md
__init__.py
config.py
main_api.py
readme.md
requirements.txt

================================================================
Repository Files
================================================================

================
File: config.py
================
'''
Date: 2024-10-13 16:54:42
LastEditors: yangyehan 1958944515@qq.com
LastEditTime: 2024-10-13 17:37:02
FilePath: /MediSearch/Users/mac/Documents/jingfangzhigu/jingfangzhigu_mutiple_agents-main/jingfangzhigu_1.0/MediSearch/config.py
Description: 
'''
# config.py
# Medisearch 配置文件
API_KEY = "5f2e2cc0-5d19-455a-8763-88eb8bb0193e"  # 请替换为您的实际 API 密钥

================
File: requirements.txt
================
fastapi
uvicorn
requests
beautifulsoup4
html2text
playwright
asyncio
textwrap
openai

================
File: readme.md
================
<!--
 * @Date: 2024-06-05 12:31:39
 * @LastEditors: yangyehan 1958944515@qq.com
 * @LastEditTime: 2024-10-14 17:20:43
 * @FilePath: /memfree-main/Users/mac/Documents/jingfangzhigu/jingfangzhigu_mutiple_agents-main/jingfangzhigu_1.0/MediSearch/readme.md
 * @Description: 
-->
# 项目名称

MediSearch 医学咨询与参考文献检索系统

# 项目运行逻辑
![逻辑运行图](./docs/drowflowchat.jpg)

## 项目简介

MediSearch 是一个集医学咨询、内容总结、大纲生成和参考文献检索于一体的综合系统。通过整合多个模块，包括与大型语言模型（LLM）的交互、网页抓取、arXiv 论文搜索和性能跟踪，MediSearch 能够为用户提供专业、详细的医学回答，并附带相关的参考文献支持。

## 功能特点

- **医学咨询**：与 MediSearchClient 交互，获取专业的医学建议。
- **内容总结**：对网页内容进行抓取和总结，生成简短易懂的摘要。
- **大纲生成**：根据对话历史，生成结构化的大纲，帮助用户理解关键点。
- **arXiv 论文检索**：自动提取关键词，搜索 arXiv 论文，提供最新的学术参考。
- **性能跟踪**：跟踪各个模块的性能，便于优化和改进。

## 目录结构

```
/project_root
├── modules/
│   ├── web_scraper.py         # 网页抓取和解析模块
│   ├── summarizer.py          # 内容总结和大纲生成模块
│   ├── performance_tracker.py # 性能跟踪模块
│   ├── llm_handler.py         # 与 LLM 交互的模块
│   ├── arxiv_search.py        # arXiv 论文搜索和解析模块
│   ├── mediator.py            # 与 MediSearchClient 交互的模块
├── main.py                    # 主程序入口
├── config.py                  # 配置文件，存储 API 密钥等信息
├── requirements.txt           # 项目依赖的第三方库
├── README.md                  # 使用说明文件（您正在阅读的文件）
```

## 安装指南

### 1. 克隆仓库

首先，克隆项目到本地：

```bash
git clone https://github.com/yourusername/medisearch.git
```

### 2. 进入项目目录

```bash
cd medisearch
```

### 3. 创建虚拟环境（可选）

建议使用虚拟环境来管理项目的依赖：

```bash
# 使用 virtualenv
python -m venv venv
source venv/bin/activate  # Linux/macOS
venv\Scripts\activate     # Windows

# 或者使用 conda
conda create -n medisearch python=3.8
conda activate medisearch
```

### 4. 安装依赖

使用以下命令安装项目所需的依赖库：

```bash
pip install -r requirements.txt
```

`requirements.txt` 文件内容：

```
requests
beautifulsoup4
html2text
```

### 5. 配置 API 密钥

在项目根目录下的 `config.py` 文件中，配置您的 API 密钥：

```python
# config.py
API_KEY = "你的API密钥"  # 请将此处替换为您的实际 API 密钥
```

> **注意**：请确保您的 API 密钥保密，不要泄露给他人。

## 使用说明

### 运行程序

在终端中，运行以下命令启动程序：

```bash
python main.py
```

### 示例调用

程序内置了一个示例的 `conversation_history`，如下所示：

```python
conversation_history = [
    "什么是高血压的治疗方法？",
    "高血压的治疗方法包括药物治疗和非药物治疗。非药物治疗包括改变生活方式，如控制体重、健康饮食、增加运动、减少压力和限制酒精摄入。药物治疗方面，常用的药物包括利尿剂、钙通道阻滞剂、血管紧张素转换酶抑制剂、血管紧张素受体拮抗剂等。根据患者的具体情况，医生会根据血压水平和存在的心血管疾病风险来决定是否需要药物治疗，并选择合适的药物进行治疗。",
    "高血压对身体的影响有哪些？"
]
```

您可以根据需要修改 `conversation_history`，输入您关心的问题。

### 输出结果

程序运行后，将输出以下内容：

- **Response**：MediSearchClient 返回的初始回答。
- **Detailed Response**：经过整合和加工的详细回复，包含参考文献支持。
- **Outline**：根据对话历史生成的结构化大纲。
- **Reference**：参考文献列表，包括标题、URL 和摘要。
- **Performance Data**：各个模块的性能数据，显示函数调用次数和耗时。

### 示例输出

```plaintext
Response: 高血压对身体的影响包括心血管系统损害，如心脏病、心力衰竭和中风；肾脏损害，可能导致肾功能衰竭；眼部损害，导致视力问题；以及动脉硬化，增加其他健康风险。

Detailed Response:
（此处将显示详细的回复，包含参考文献）

Outline:
- 高血压的治疗方法
  - 非药物治疗
    - 控制体重
    - 健康饮食
    - 增加运动
    - 减少压力
    - 限制酒精摄入
  - 药物治疗
    - 利尿剂
    - 钙通道阻滞剂
    - 血管紧张素转换酶抑制剂
    - 血管紧张素受体拮抗剂
- 高血压对身体的影响
  - 心血管系统损害
  - 肾脏损害
  - 眼部损害
  - 动脉硬化

Reference:
ID    标题                                 URL                                         摘要
---------------------------------------------------------------------------------------------------
[1]   高血压的危害及预防措施                  http://example.com/hypertension            高血压是心血管疾病的主要风险因素...
---------------------------------------------------------------------------------------------------
[2]   控制血压的重要性                        http://example.com/bloodpressurecontrol    控制血压可以有效减少中风和心脏病的风险...
---------------------------------------------------------------------------------------------------

Performance Data:
函数名                                     调用次数    总时间(秒)           平均时间(秒)
-------------------------------------------------------------------------------------------
generate_response                         5          12.34              2.47
fetch_and_parse_single_url                3          6.78               2.26
...
```

## 模块说明

### 1. modules/web_scraper.py

用于抓取网页内容，并解析为纯文本。

### 2. modules/summarizer.py

负责将 HTML 内容转换为 Markdown 格式，并使用 LLM 生成摘要和大纲。

### 3. modules/performance_tracker.py

提供性能跟踪装饰器和性能数据打印函数，帮助监控各模块的性能。

### 4. modules/llm_handler.py

与大型语言模型（LLM）交互，发送请求并获取响应。

### 5. modules/arxiv_search.py

从对话历史中提取关键词，搜索 arXiv 论文，并解析搜索结果。

### 6. modules/mediator.py

与 MediSearchClient 交互，获取医学建议和相关文章。

## 注意事项

- **API 密钥安全**：请确保您的 API 密钥安全，不要将其上传到公共仓库或分享给他人。
- **依赖库版本**：请确保安装的依赖库版本与项目兼容，必要时可在 `requirements.txt` 中指定版本号。
- **模型文件**：确保 `models/custom_llm.py` 文件存在且可用，因为 `LLMHandler` 模块依赖于它。

## 常见问题

### 1. 程序无法运行，提示缺少模块或包

请确保已正确安装所有依赖库：

```bash
pip install -r requirements.txt
```

### 2. 收到 API 调用错误或权限错误

请检查您的 API 密钥是否正确配置，以及是否有调用权限。

### 3. 输出结果不完整或有误

可能是由于网络问题或 API 服务异常，请稍后重试。

## 联系方式

如有任何问题或建议，欢迎联系：

- **Email**: 1958944515@qq.com
- **GitHub**: [15392778677]()

## 许可证

此项目遵循 MIT 许可证。

---

感谢您使用 MediSearch！希望本项目能对您的学习和工作有所帮助。

```
优化前：
+-----------------------------------------+-------+----------------+--------------+
| Function                                | Calls | Total Time(s)  | Avg Time(s)  |
+-----------------------------------------+-------+----------------+--------------+
| fetch_medicine_advice_with_history      | 1     | 5.27           | 5.27         |
| fetch_and_parse_single_url              | 7     | 8.59           | 1.23         |
| summarize_html_content                  | 7     | 144.31         | 20.62        |
| generate_outline                        | 1     | 8.97           | 8.97         |
| MediSearch                              | 1     | 167.15         | 167.15       |
+-----------------------------------------+-------+----------------+--------------+
```



```
优化后：
+-----------------------------------------+-------+----------------+--------------+
| Function                                | Calls | Total Time(s)  | Avg Time(s)  |
+-----------------------------------------+-------+----------------+--------------+
| fetch_medicine_advice_with_history      | 1     | 7.04           | 7.04         |
| fetch_and_parse_single_url              | 5     | 8.57           | 1.71         |
| html_to_markdown                        | 5     | 0.01           | 0.00         |
| summarize_html_content                  | 5     | 39.48          | 7.90         |
| generate_outline                        | 1     | 7.43           | 7.43         |
| MediSearch                              | 1     | 23.38          | 23.38        |
+-----------------------------------------+-------+----------------+--------------+
```

# 智谷搜索response返回内容预览：
#### 研究背景

中草药与人工智能技术的结合代表了中医药研究的一个重要发展方向。随着人工智能技术的快速进步，尤其是在数据分析和模式识别方面，它为中草药的研究提供了新的视角和工具。中草药的复杂性和多样性使得传统的研究方法面临巨大挑战，而人工智能可以通过量化分析、机器学习等方法来解析中草药的有效成分及其在治疗特定疾病中的作用。

全面的领域分析显示，利用人工智能推动中草药研究的发展趋势正在形成，这不仅丰富了中草药的科学基础，也提高了其在全球医疗体系中的认可度。

#### 研究成果

根据最新的研究，中国在中草药领域的学术影响力显著，发表量占比达到54.35%。这表明中国在该领域的研究中发挥了关键作用，推动了相关理论和实践的进步。

- **发表量占比：** 54.35%
- **研究的关键作用：** 促进中草药的国际化，增强对其疗效的科学验证。

#### 重点研究疾病

在中草药应用中，有几个疾病的研究被认为尤为重要，具体包括：

1. **肝细胞癌**：中草药在肝细胞癌的辅助治疗中显示出良好效果，相关的配方和疗效机制研究正在增加。

2. **化学和药物性肝损伤**：研究发现某些中草药能够减轻药物引起的肝损伤，为药物安全提供了新的思路。

3. **Papillon-Lefèvre病**：该病罕见且复杂，中草药在综合治疗中的作用引起了关注，临床研究正在探索其潜在疗效。

4. **帕金森病**：研究表明，一些中草药可能有助于缓解帕金森病患者的症状，为神经退行性疾病的治疗提供了新方向。

5. **厌食症**：中草药在促进食欲和改善消化方面的潜力，使其在厌食症的治疗中逐渐成为研究重点。

#### 研究的意义

中草药与人工智能的结合为科学研究带来了重大意义：

- **重要信息提供**：通过计量分析和数据挖掘，提供了中草药在不同疾病治疗中作用的新见解，帮助研究人员更好地理解中草药的机制。

- **促进创新思维的发展**：借助人工智能的强大功能，启发新的研究方向和思路，推动中草药研究的多学科融合，进一步拓宽其应用领域。

这些研究不仅提升了中草药的科学地位，也为现代医学实践提供了宝贵的补充，展示了传统医学与现代科技结合的无限潜力。


<div style="text-align: center;">
    <a href="https://jingfang-images-1322234581.cos.ap-beijing.myqcloud.com/jfzg/1845746644262117376.png" target="_blank">
        <img src="https://jingfang-images-1322234581.cos.ap-beijing.myqcloud.com/jfzg/1845746644262117376.png"  style="max-width: 100%; height: auto;">
    </a>
</div>




### Related Papers to Organize Forms(English)
| Title | URL | Keywords | Summary |
|-------|-----|----------|---------|
| Sequential Condition Evolved Interaction Knowledge Graph for Traditional   Chinese Medicine Recommendation | [Link](http://arxiv.org/abs/2305.17866v2) | cs.AI, cs.IR |   Traditional Chinese Medicine (TCM) has a rich history of utilizing natural herbs to treat a diversity of illnesses. |
| TCM-FTP: Fine-Tuning Large Language Models for Herbal Prescription   Prediction | [Link](http://arxiv.org/abs/2407.10510v1) | cs.CL, cs.AI, cs.CE |   Traditional Chinese medicine (TCM) relies on specific combinations of herbs in prescriptions to treat symptoms and signs, a practice that spans thousands of years. |
| Herb-Drug Interactions: A Holistic Decision Support System in Healthcare | [Link](http://arxiv.org/abs/2306.15365v1) | cs.AI |   Complementary and alternative medicine are commonly used concomitantly with conventional medications leading to adverse drug reactions and even fatality in some cases. |
| Predicting Document Coverage for Relation Extraction | [Link](http://arxiv.org/abs/2111.13611v1) | cs.CL, cs.AI |   This paper presents a new task of predicting the coverage of a text document for relation extraction (RE): does the document contain many relational tuples for a given entity? Coverage predictions are useful in selecting the best documents for knowledge base construction with large input corpora. |
| Benchmarking Robot Manipulation with the Rubik's Cube | [Link](http://arxiv.org/abs/2202.07074v1) | cs.RO, cs.AI |   Benchmarks for robot manipulation are crucial to measuring progress in the field, yet there are few benchmarks that demonstrate critical manipulation skills, possess standardized metrics, and can be attempted by a wide array of robot platforms. |
| Free-hand gas identification based on transfer function ratios without   gas flow control | [Link](http://arxiv.org/abs/1812.05193v1) | physics.app-ph |   Gas identification is one of the most important functions of gas sensor systems. |


### 相关论文整理表格(Chinese)
| 标题 | URL | 关键词 | 摘要 |
|-------|-----|----------|---------|
| 演化交互知识图谱的顺序条件用于传统中医推荐 | [链接](http://arxiv.org/abs/2305.17866v2) | cs.AI, cs.IR |   传统中医（TCM）有着利用天然草药治疗多种疾病的丰富历史。 |
| TCM-FTP：用于草药处方预测的大型语言模型微调 | [链接](http://arxiv.org/abs/2407.10510v1) | cs.CL, cs.AI, cs.CE |   传统中医（TCM）依赖于特定的草药组合来治疗症状和体征，这一实践已有数千年的历史。 |
| 草药-药物相互作用：医疗保健中的整体决策支持系统 | [链接](http://arxiv.org/abs/2306.15365v1) | cs.AI |   传统与替代医学通常与常规药物同时使用，导致不良药物反应，甚至在某些情况下导致死亡。 |
| 关系提取的文档覆盖率预测 | [链接](http://arxiv.org/abs/2111.13611v1) | cs.CL, cs.AI |   本文提出了一项新的任务，即预测文本文档在关系提取（RE）方面的覆盖率：该文档是否包含许多与给定实体相关的元组？覆盖率预测对于从大量输入语料库中选择最佳文档以构建知识库非常有用。 |
| 使用魔方基准测试机器人操作 | [链接](http://arxiv.org/abs/2202.07074v1) | cs.RO, cs.AI |   机器人操作的基准测试对于衡量该领域的进展至关重要，但能展示关键操作技能、拥有标准化指标并可由多种机器人平台尝试的基准测试仍然较少。 |
| 基于传递函数比的自由手气体识别，无需气体流量控制 | [链接](http://arxiv.org/abs/1812.05193v1) | physics.app-ph |   气体识别是气体传感器系统最重要的功能之一。 |

================
File: README_English.md
================
# MediSearch


## flowchart
![逻辑运行图](./docs/flowchat_eng.png)

MediSearch is a medical research assistant that integrates multiple modules to provide comprehensive medical advice, academic paper searches, summarization, and visualization functionalities. It leverages language models to process user queries, fetch relevant information from various sources, and present it in an organized manner.

## Table of Contents

- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [Modules Overview](#modules-overview)
- [Contributing](#contributing)
- [License](#license)

## Features

- **Medical Advice Retrieval**: Fetches medical advice based on user conversation history using an AI model.
- **Academic Paper Search**: Searches for relevant papers on arXiv using extracted keywords.
- **Content Summarization**: Summarizes web content and academic papers for easier understanding.
- **Visualization**: Generates diagrams and mind maps using Mermaid syntax and converts them into images.
- **Performance Tracking**: Tracks the performance of various functions and the overall program execution time.

## Installation

### Prerequisites

- Python 3.7 or higher
- pip package manager

### Steps

1. **Clone the repository**

   ```bash
   git clone https://github.com/yourusername/MediSearch.git
   ```

2. **Navigate to the project directory**

   ```bash
   cd MediSearch
   ```

3. **Create a virtual environment (optional but recommended)**

   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows use `venv\Scripts\activate`
   ```

4. **Install the required packages**

   ```bash
   pip install -r requirements.txt
   ```

5. **Install Playwright browsers**

   The application uses Playwright for rendering Mermaid diagrams. Install the necessary browsers:

   ```bash
   playwright install
   ```

6. **Set up the configuration**

   - Rename `config_template.py` to `config.py`.
   - Replace placeholders with your actual API keys and configurations.

     ```python
     # config.py
     API_KEY = "your_medisearch_api_key"
     ```

   **Note**: Keep your API keys secure and do not share them publicly.

## Usage

To run the MediSearch application, execute:

```bash
python main.py
```

### Example

In `main.py`, you can modify the `conversation_history` variable to include your query:

```python
# main.py

if __name__ == "__main__":
    start_program_timer()

    # Example conversation history
    conversation_history = [
        "What are the latest research directions in traditional Chinese herbal medicine models?"
    ]

    result = asyncio.run(MediSearch(conversation_history))
    print(result["response"])

    end_program_timer()

    print_performance_data()
```

The application will process the query and provide a detailed response, including summaries, visualizations, and references.

## Project Structure

```
MediSearch/
├── main.py
├── config.py
├── models/
│   └── custom_llm.py
├── modules/
│   ├── arxiv_search.py
│   ├── flowchat.py
│   ├── llm_handler.py
│   ├── Markdown.py
│   ├── mediator.py
│   ├── performance_tracker.py
│   ├── summarizer.py
│   └── web_scraper.py
├── docs/
│   └── diagram.jpg
├── requirements.txt
└── README.md
```

## Modules Overview

### `main.py`

The entry point of the application. It orchestrates the flow by calling various modules to process the conversation history and generate the final output.

### `config.py`

Contains configuration variables such as API keys. **Ensure you keep your API keys secure and do not share them publicly.**

### `models/custom_llm.py`

Defines a custom language model class that integrates with the OpenAI API to generate responses based on prompts.

### `modules/`

Contains various modules that handle specific tasks:

- **`arxiv_search.py`**: Handles keyword extraction from conversation history and searches for relevant papers on arXiv.
- **`flowchat.py`**: Generates diagrams and mind maps using Mermaid syntax and uploads images to a server.
- **`llm_handler.py`**: Manages prompts and responses with the language model.
- **`Markdown.py`**: Contains utility functions for rendering Markdown content and parsing Mermaid syntax.
- **`mediator.py`**: Coordinates with the `MediSearchClient` to fetch medical advice and related articles.
- **`performance_tracker.py`**: Tracks the performance of functions and the overall program execution time.
- **`summarizer.py`**: Summarizes HTML content and generates outlines based on conversation history.
- **`web_scraper.py`**: Fetches and parses web content from URLs.

## Contributing

Contributions are welcome! Please follow these steps:

1. **Fork the repository**

2. **Create a new branch**

   ```bash
   git checkout -b feature/your-feature-name
   ```

3. **Make your changes**

4. **Commit your changes**

   ```bash
   git commit -m "Description of your changes"
   ```

5. **Push to the branch**

   ```bash
   git push origin feature/your-feature-name
   ```

6. **Submit a pull request**

   Provide a detailed description of your changes and any related issues.

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

**Note**: Ensure that you have a `requirements.txt` file listing all the Python dependencies required for the project. Also, be cautious with any API keys or sensitive information in your configuration files; they should not be included in commits or shared publicly.

================
File: main_api.py
================
# api_service.py
import asyncio
from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse
from fastapi.middleware.cors import CORSMiddleware
from typing import List
import json
from concurrent.futures import ThreadPoolExecutor

from modules.mediator import Mediator
from modules.summarizer import Summarizer
from modules.web_scraper import WebScraper
from modules.arxiv_search import ArxivSearch
from modules.performance_tracker import track_performance
from modules.llm_handler import LLMHandler, Res
from modules.flowchat import MermaidToImageUploader
from modules.Markdown import render_markdown_image, parse_mermaid_syntax
from config import API_KEY

app = FastAPI()

# 允许所有源访问（根据需要进行限制）
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

def wrap_text(text, width):
    import textwrap
    return textwrap.wrap(text, width)

@track_performance
def convert_to_markdown(arxiv_reference):
    markdown  = "| Title | URL | Keywords | Summary |\n"
    markdown += "|-------|-----|----------|---------|\n"
    for ref in arxiv_reference:
        title = ref['title'].replace('\n', ' ')
        url = ref['url']
        keywords = ', '.join(ref['keywords'])
        summary = ref['summary'].replace('\n', ' ')
        markdown += f"| {title} | [Link]({url}) | {keywords} | {summary} |\n"
    return markdown

@track_performance
def conver_to_chinese(markdown: str):
    prompt = f"""
    请将以下 markdown 表格翻译为中文，并以 markdown 格式输出：
    注意只能输出翻译后的表格，不要添加多余内容！
    原始表格：
    {markdown}
    输出：
    """

    llm_handler = LLMHandler()
    result = llm_handler.generate_response(prompt)
    return result

@track_performance
async def generate_detailed_response(result, conversation_history, executor):
    response = result.get('response', '')
    outline = result.get('outline', '')
    reference = result.get('reference', [])
    arxiv_reference = result.get('arxiv_reference', [])

    reference_text = "\n\n".join([
        f"Title: {ref['title']}\nURL: {ref['url']}\nSummary: {ref['summary']}"
        for ref in reference
    ])

    arxiv_reference_text = "\n\n".join([
        f"Title: {ref['title']}\nURL: {ref['url']}\nKeywords: {', '.join(ref['keywords'])}\nSummary: {ref['summary']}"
        for ref in arxiv_reference
    ])

    res = Res(response, outline, reference_text, arxiv_reference_text, conversation_history)
    llm_handler = LLMHandler()

    # 使用线程池并行执行 LLM 调用
    detailed_response_future = asyncio.get_event_loop().run_in_executor(
        executor, llm_handler.generate_response, llm_handler.SearchPrompt(res)
    )
    print("detailed response future created")

    # 并发获取图表和转换 markdown
    graph_and_markdown = await asyncio.gather(
        get_Graph(res, executor),
        asyncio.get_event_loop().run_in_executor(executor, convert_to_markdown, arxiv_reference)
    )
    print("graph and markdown future created")

    detailed_response = await detailed_response_future

    graph_result, reference_table_english = graph_and_markdown

    # 生成图表
    if graph_result['stateCode'] == 200:
        detailed_response += f"\n\n{render_markdown_image(graph_result['image_url'])}\n\n"

    # 添加参考文献表格
    reference_table_chinese = await asyncio.get_event_loop().run_in_executor(
        executor, conver_to_chinese, reference_table_english
    )
    print("reference table future created")

    detailed_response += "\n\n### 相关论文整理表格 (英文)\n"
    detailed_response += reference_table_english
    detailed_response += "\n\n### 相关论文整理表格 (中文)\n"
    detailed_response += reference_table_chinese

    return detailed_response

@track_performance
async def get_Graph(res: Res, executor) -> dict:
    llm_handler = LLMHandler()
    prompt = llm_handler.Mermaid_Graph_Prompt(res)
    # 使用线程池执行 generate_response
    result = await asyncio.get_event_loop().run_in_executor(
        executor, llm_handler.generate_response, prompt
    )
    mermaid_code = parse_mermaid_syntax(result)
    uploader = MermaidToImageUploader()
    image_url, error = await uploader.get_image_url(mermaid_code)
    if image_url:
        return {"stateCode": 200, "image_url": image_url}
    else:
        return {"stateCode": 500, "image_url": None, "error": error}

@track_performance
async def MediSearch(conversation_history, send_update):
    mediator = Mediator(api_key=API_KEY)
    summarizer = Summarizer()
    web_scraper = WebScraper()
    arxiv_search = ArxivSearch()

    # 获取医学建议
    advice_response = mediator.fetch_medicine_advice_with_history(conversation_history)
    if advice_response['last_text_event']:
        conversation_history.append(advice_response['last_text_event'])

    # 创建线程池
    executor = ThreadPoolExecutor(max_workers=10)

    try:
        # 开始任务

        # 生成大纲
        outline_future = asyncio.get_event_loop().run_in_executor(
            executor, summarizer.generate_outline, conversation_history
        )

        # 获取 arXiv 文章
        def fetch_arxiv():
            keywords = arxiv_search.fetch_keywords_from_conversation(conversation_history)
            arxiv_response = arxiv_search.search_arxiv_papers(keywords)
            arxiv_articles = arxiv_search.parse_arxiv_response(arxiv_response)
            return arxiv_articles

        arxiv_future = asyncio.get_event_loop().run_in_executor(
            executor, fetch_arxiv
        )

        # 发送初始结果
        async def send_initial_results():
            outline = await outline_future
            await send_update(json.dumps({"type": "outline", "data": outline}))

            arxiv_articles = await arxiv_future
            await send_update(json.dumps({"type": "arxiv_reference", "data": arxiv_articles}))

        initial_results_task = asyncio.create_task(send_initial_results())

        # 获取并总结文章
        def fetch_and_summarize(article):
            html_content = web_scraper.fetch_and_parse_single_url(article.get('url', ''))
            summary = summarizer.summarize_html_content(article.get('title', ''), html_content)
            print("summary finished")
            return {
                'title': article.get('title', 'N/A'),
                'url': article.get('url', 'N/A'),
                'summary': summary
            }

        # 使用线程池并发处理文章
        article_futures = [
            asyncio.get_event_loop().run_in_executor(
                executor, fetch_and_summarize, article
            ) for article in advice_response['articles']
        ]
        articles_info = await asyncio.gather(*article_futures)

        # 等待初始结果发送完成
        await initial_results_task
        print("initial results sent")

        # 准备最终结果
        result = {
            "response": advice_response['last_text_event'],
            "outline": await outline_future,
            "reference": articles_info,
            "arxiv_reference": await arxiv_future
        }

        # 生成详细响应
        detailed_result = await generate_detailed_response(result, conversation_history, executor)
        print("detailed result generated")
        result['response'] = detailed_result

        # 发送详细响应
        await send_update(json.dumps({"type": "result", "data": result}))

    finally:
        # 关闭线程池
        executor.shutdown()

@app.post("/medisearch")
async def medisearch_endpoint(query: dict):
    """
    MediSearch 接口，接受 'conversation_history' 字段。
    在数据生成后以流的方式返回给客户端。
    """
    conversation_history = query.get('conversation_history', [])

    async def event_generator():
        queue = asyncio.Queue()

        async def send_update(message):
            await queue.put(message)

        medisearch_task = asyncio.create_task(MediSearch(conversation_history, send_update))

        while True:
            message = await queue.get()
            yield f"data: {message}\n\n"

            if medisearch_task.done() and queue.empty():
                break

    return StreamingResponse(event_generator(), media_type="text/event-stream")

================
File: README_chinese.md
================
# MediSearch 医学咨询与参考文献检索系统

## Flowchat 运行逻辑图
![逻辑运行图](./docs/flowchat_chinese.png)


## 项目简介

MediSearch 是一个集医学咨询、内容总结、大纲生成和参考文献检索于一体的综合系统。通过整合多个模块，包括与大型语言模型（LLM）的交互、网页抓取、arXiv 论文搜索、图表生成和性能跟踪，MediSearch 能够为用户提供专业、详细的医学回答，并附带相关的参考文献和可视化支持。

## 功能特点

- **医学咨询**：与 MediSearchClient 交互，获取专业的医学建议。
- **内容总结**：对网页内容进行抓取和总结，生成简短易懂的摘要。
- **大纲生成**：根据对话历史，生成结构化的大纲，帮助用户理解关键点。
- **arXiv 论文检索**：自动提取关键词，搜索 arXiv 论文，提供最新的学术参考。
- **可视化图表**：使用 Mermaid 语法生成流程图或思维导图，并将其转换为图片。
- **性能跟踪**：跟踪各个模块的性能，便于优化和改进。

## 目录

- [项目简介](#项目简介)
- [功能特点](#功能特点)
- [项目结构](#项目结构)
- [安装指南](#安装指南)
- [使用说明](#使用说明)
- [示例输出](#示例输出)
- [性能优化](#性能优化)
- [模块说明](#模块说明)
- [注意事项](#注意事项)
- [常见问题](#常见问题)
- [联系方式](#联系方式)
- [许可证](#许可证)

## 项目结构

```
/project_root
├── main.py                    # 主程序入口
├── config.py                  # 配置文件，存储 API 密钥等信息
├── models/
│   └── custom_llm.py          # 自定义语言模型模块
├── modules/
│   ├── arxiv_search.py        # arXiv 论文搜索和解析模块
│   ├── flowchat.py            # Mermaid 图表生成与图片上传模块
│   ├── llm_handler.py         # 与 LLM 交互的模块
│   ├── Markdown.py            # Markdown 渲染和 Mermaid 解析模块
│   ├── mediator.py            # 与 MediSearchClient 交互的模块
│   ├── performance_tracker.py # 性能跟踪模块
│   ├── summarizer.py          # 内容总结和大纲生成模块
│   └── web_scraper.py         # 网页抓取和解析模块
├── docs/
│   └── drowflowchat.jpg       # 项目运行逻辑图
├── requirements.txt           # 项目依赖的第三方库
├── README.md                  # 使用说明文件（您正在阅读的文件）
```

## 安装指南

### 1. 克隆仓库

首先，克隆项目到本地：

```bash
git clone https://github.com/yourusername/medisearch.git
```

### 2. 进入项目目录

```bash
cd medisearch
```

### 3. 创建虚拟环境（可选）

建议使用虚拟环境来管理项目的依赖：

```bash
# 使用 virtualenv
python -m venv venv
source venv/bin/activate  # Linux/macOS
venv\Scripts\activate     # Windows

# 或者使用 conda
conda create -n medisearch python=3.8
conda activate medisearch
```

### 4. 安装依赖

使用以下命令安装项目所需的依赖库：

```bash
pip install -r requirements.txt
```

`requirements.txt` 文件内容示例：

```
requests
beautifulsoup4
html2text
playwright
asyncio
```

> **注意**：安装 Playwright 后，还需要安装浏览器驱动：

```bash
playwright install
```

### 5. 配置 API 密钥

在项目根目录下的 `config.py` 文件中，配置您的 API 密钥：

```python
# config.py
API_KEY = "你的API密钥"  # 请将此处替换为您的实际 API 密钥
```

> **注意**：请确保您的 API 密钥保密，不要泄露给他人。

## 使用说明

### 运行程序

在终端中，运行以下命令启动程序：

```bash
python main.py
```

### 示例调用

程序内置了一个示例的 `conversation_history`，如下所示：

```python
conversation_history = [
    "中草药大模型最新的研究方向是什么？"
]
```

您可以根据需要修改 `conversation_history`，输入您关心的问题。

### 输出结果

程序运行后，将输出以下内容：

- **Response**：MediSearchClient 返回的初始回答。
- **Detailed Response**：经过整合和加工的详细回复，包含参考文献支持和可视化图表。
- **Performance Data**：各个模块的性能数据，显示函数调用次数和耗时。

## 示例输出

### Detailed Response

#### 研究背景

中草药与人工智能技术的结合代表了中医药研究的一个重要发展方向。随着人工智能技术的快速进步，尤其是在数据分析和模式识别方面，它为中草药的研究提供了新的视角和工具。中草药的复杂性和多样性使得传统的研究方法面临巨大挑战，而人工智能可以通过量化分析、机器学习等方法来解析中草药的有效成分及其在治疗特定疾病中的作用。

全面的领域分析显示，利用人工智能推动中草药研究的发展趋势正在形成，这不仅丰富了中草药的科学基础，也提高了其在全球医疗体系中的认可度。

#### 研究成果

根据最新的研究，中国在中草药领域的学术影响力显著，发表量占比达到54.35%。这表明中国在该领域的研究中发挥了关键作用，推动了相关理论和实践的进步。

- **发表量占比：** 54.35%
- **研究的关键作用：** 促进中草药的国际化，增强对其疗效的科学验证。

#### 重点研究疾病

在中草药应用中，有几个疾病的研究被认为尤为重要，具体包括：

1. **肝细胞癌**：中草药在肝细胞癌的辅助治疗中显示出良好效果，相关的配方和疗效机制研究正在增加。

2. **化学和药物性肝损伤**：研究发现某些中草药能够减轻药物引起的肝损伤，为药物安全提供了新的思路。

3. **Papillon-Lefèvre病**：该病罕见且复杂，中草药在综合治疗中的作用引起了关注，临床研究正在探索其潜在疗效。

4. **帕金森病**：研究表明，一些中草药可能有助于缓解帕金森病患者的症状，为神经退行性疾病的治疗提供了新方向。

5. **厌食症**：中草药在促进食欲和改善消化方面的潜力，使其在厌食症的治疗中逐渐成为研究重点。

#### 研究的意义

中草药与人工智能的结合为科学研究带来了重大意义：

- **重要信息提供**：通过计量分析和数据挖掘，提供了中草药在不同疾病治疗中作用的新见解，帮助研究人员更好地理解中草药的机制。

- **促进创新思维的发展**：借助人工智能的强大功能，启发新的研究方向和思路，推动中草药研究的多学科融合，进一步拓宽其应用领域。

这些研究不仅提升了中草药的科学地位，也为现代医学实践提供了宝贵的补充，展示了传统医学与现代科技结合的无限潜力。

#### 可视化图表

<div style="text-align: center;">
    <a href="https://jingfang-images-1322234581.cos.ap-beijing.myqcloud.com/jfzg/1845746644262117376.png" target="_blank">
        <img src="https://jingfang-images-1322234581.cos.ap-beijing.myqcloud.com/jfzg/1845746644262117376.png"  style="max-width: 100%; height: auto;">
    </a>
</div>

#### 相关论文整理表格

**英文版**

| Title | URL | Keywords | Summary |
|-------|-----|----------|---------|
| Sequential Condition Evolved Interaction Knowledge Graph for Traditional Chinese Medicine Recommendation | [Link](http://arxiv.org/abs/2305.17866v2) | cs.AI, cs.IR | Traditional Chinese Medicine (TCM) has a rich history of utilizing natural herbs to treat a diversity of illnesses. |
| TCM-FTP: Fine-Tuning Large Language Models for Herbal Prescription Prediction | [Link](http://arxiv.org/abs/2407.10510v1) | cs.CL, cs.AI, cs.CE | Traditional Chinese medicine (TCM) relies on specific combinations of herbs in prescriptions to treat symptoms and signs, a practice that spans thousands of years. |
| Herb-Drug Interactions: A Holistic Decision Support System in Healthcare | [Link](http://arxiv.org/abs/2306.15365v1) | cs.AI | Complementary and alternative medicine are commonly used concomitantly with conventional medications leading to adverse drug reactions and even fatality in some cases. |

**中文版**

| 标题 | 链接 | 关键词 | 摘要 |
|-------|-----|----------|---------|
| 演化交互知识图谱的顺序条件用于传统中医推荐 | [链接](http://arxiv.org/abs/2305.17866v2) | cs.AI, cs.IR | 传统中医（TCM）有着利用天然草药治疗多种疾病的丰富历史。 |
| TCM-FTP：用于草药处方预测的大型语言模型微调 | [链接](http://arxiv.org/abs/2407.10510v1) | cs.CL, cs.AI, cs.CE | 传统中医（TCM）依赖于特定的草药组合来治疗症状和体征，这一实践已有数千年的历史。 |
| 草药-药物相互作用：医疗保健中的整体决策支持系统 | [链接](http://arxiv.org/abs/2306.15365v1) | cs.AI | 传统与替代医学通常与常规药物同时使用，导致不良药物反应，甚至在某些情况下导致死亡。 |

### Performance Data

```
优化前：
+-----------------------------------------+-------+----------------+--------------+
| Function                                | Calls | Total Time(s)  | Avg Time(s)  |
+-----------------------------------------+-------+----------------+--------------+
| fetch_medicine_advice_with_history      | 1     | 5.27           | 5.27         |
| fetch_and_parse_single_url              | 7     | 8.59           | 1.23         |
| summarize_html_content                  | 7     | 144.31         | 20.62        |
| generate_outline                        | 1     | 8.97           | 8.97         |
| MediSearch                              | 1     | 167.15         | 167.15       |
+-----------------------------------------+-------+----------------+--------------+
```

```
优化后：
+-----------------------------------------+-------+----------------+--------------+
| Function                                | Calls | Total Time(s)  | Avg Time(s)  |
+-----------------------------------------+-------+----------------+--------------+
| fetch_medicine_advice_with_history      | 1     | 7.04           | 7.04         |
| fetch_and_parse_single_url              | 5     | 8.57           | 1.71         |
| html_to_markdown                        | 5     | 0.01           | 0.00         |
| summarize_html_content                  | 5     | 39.48          | 7.90         |
| generate_outline                        | 1     | 7.43           | 7.43         |
| MediSearch                              | 1     | 23.38          | 23.38        |
+-----------------------------------------+-------+----------------+--------------+
```

## 性能优化

通过对异步函数的优化和合理的并发处理，程序的整体性能得到了显著提升。优化后的程序在保持功能完整的情况下，减少了各模块的平均执行时间，提高了用户体验。

## 模块说明

### 1. modules/web_scraper.py

用于抓取网页内容，并解析为纯文本。

### 2. modules/summarizer.py

负责将 HTML 内容转换为 Markdown 格式，并使用 LLM 生成摘要和大纲。

### 3. modules/performance_tracker.py

提供性能跟踪装饰器和性能数据打印函数，帮助监控各模块的性能。

### 4. modules/llm_handler.py

与大型语言模型（LLM）交互，发送请求并获取响应。

### 5. modules/arxiv_search.py

从对话历史中提取关键词，搜索 arXiv 论文，并解析搜索结果。

### 6. modules/mediator.py

与 MediSearchClient 交互，获取医学建议和相关文章。

### 7. modules/flowchat.py

生成 Mermaid 图表，并将其转换为图片上传到服务器。

### 8. modules/Markdown.py

包含用于渲染 Markdown 内容和解析 Mermaid 语法的实用函数。

## 注意事项

- **API 密钥安全**：请确保您的 API 密钥安全，不要将其上传到公共仓库或分享给他人。
- **依赖库版本**：请确保安装的依赖库版本与项目兼容，必要时可在 `requirements.txt` 中指定版本号。
- **模型文件**：确保 `models/custom_llm.py` 文件存在且可用，因为 `LLMHandler` 模块依赖于它。
- **Playwright 安装**：在使用 `flowchat.py` 模块时，需要确保已正确安装 Playwright 及其依赖的浏览器驱动。

## 常见问题

### 1. 程序无法运行，提示缺少模块或包

请确保已正确安装所有依赖库：

```bash
pip install -r requirements.txt
```

### 2. 收到 API 调用错误或权限错误

请检查您的 API 密钥是否正确配置，以及是否有调用权限。

### 3. 输出结果不完整或有误

可能是由于网络问题或 API 服务异常，请稍后重试。

### 4. Mermaid 图表无法生成

请确保已正确安装 Playwright，并执行以下命令安装浏览器驱动：

```bash
playwright install
```

## 联系方式

如有任何问题或建议，欢迎联系：

- **Email**: 1958944515@qq.com
- **GitHub**: [15392778677]()

## 许可证

此项目遵循 MIT 许可证。

---

感谢您使用 MediSearch！希望本项目能对您的学习和工作有所帮助。


## 项目详细架构逻辑：
![](./docs/detailflowchat.png)

================
File: models/custom_llm.py
================
'''
Date: 2024-10-13 17:48:43
LastEditors: yangyehan 1958944515@qq.com
LastEditTime: 2024-10-18 16:44:49
FilePath: /MediSearch/models/custom_llm.py
Description: 
'''
# models/custom_llm.py
import sys
import asyncio
from typing import Any, List, Dict, Mapping, Optional
from langchain.callbacks.manager import CallbackManagerForLLMRun
from langchain.llms.base import LLM
from openai import OpenAI

class CustomLLM(LLM):
    logging: bool = False
    output_keys: List[str] = ["output"]
    llm_type: str = "gpt-4o-mini-2024-07-18"
    history: List[Mapping[str, str]] = []

    @property
    def _llm_type(self) -> str:
        return self.llm_type

    def log(self, log_str):
        if self.logging:
            print(log_str)

    def add_history(self, role: str, content: str):
        """添加历史对话到history列表中。"""
        self.history.append({"role": role, "content": content})

    def add_multiple_histories(self, histories: List[Dict[str, str]]):
        """一次性添加多条历史对话到history列表中。"""
        self.history.extend(histories)
    
    def check_history(self) -> List[Mapping[str, str]]:
        """返回当前的历史对话记录。"""
        return self.history.copy()

    def clear_history(self):
        """清空历史对话。"""
        self.history.clear()

    async def _call_async(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
    ) -> str:
        return await asyncio.to_thread(self._call, prompt)
    
    def _call(
        self,
        prompt: str,
        stop: Optional[List[str]] = None,
        run_manager: Optional[CallbackManagerForLLMRun] = None,
    ) -> str:
        self.log('----------' + self._llm_type + '----------> llm._call()')
        self.log(prompt)

        # 先将用户的输入添加到history中
        self.add_history("user", prompt)

        # 然后直接使用更新后的history赋值给messages
        messages = self.history.copy() 

        try:
            client = OpenAI(
                api_key='YOUR_API_KEY_HERE',  # 请确保使用安全的方式存储API密钥
                base_url='https://api.gpt.ge/v1/'
            )
            response = client.chat.completions.create(
                messages=messages,
                model="gpt-4o-mini-2024-07-18",
            )
            
        except Exception as e:
            print("发生错误:", e)
            response = None

        if response is None:
            response_content = ""
        else:
            response_content = response.choices[0].message.content
            self.add_history("assistant", response_content)  # 将系统回复作为历史记录添加

        return response_content

    @property
    def _identifying_params(self) -> Mapping[str, Any]:
        return {"n": 10}

if __name__ == "__main__":
    llm = CustomLLM()
    result = asyncio.run(llm._call_async("你是什么模型？"))
    print(result)

================
File: modules/web_scraper.py
================
'''
Date: 2024-10-13 16:53:30
LastEditors: yangyehan 1958944515@qq.com
LastEditTime: 2024-10-13 18:33:54
FilePath: /MediSearch/Users/mac/Documents/jingfangzhigu/jingfangzhigu_mutiple_agents-main/jingfangzhigu_1.0/MediSearch/modules/web_scraper.py
Description: 用于处理网页抓取任务的模块，增加了可复用性。
'''
import sys
sys.path.append('..')
import requests
from bs4 import BeautifulSoup

class WebScraper:
    def fetch_and_parse_single_url(self, url: str) -> str:
        """
        获取单个 URL 的所有非 HTML 文本内容。

        参数：
        - url (str): 要获取的 URL。

        返回值：
        - str: URL 的所有非 HTML 文本内容。
        """
        try:
            response = requests.get(url)
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'html.parser')
                text_content = soup.get_text(separator=' ', strip=True)
                return text_content
            else:
                return "加载内容失败。"
        except Exception as e:
            return f"加载内容时出错：{e}"

================
File: modules/mediator.py
================
# modules/mediator.py
import sys
sys.path.append('..')
from medisearch_client import MediSearchClient
import uuid
from modules.performance_tracker import track_performance
from config import API_KEY

class Mediator:
    def __init__(self, api_key: str):
        self.api_key = api_key

    @track_performance
    def fetch_medicine_advice_with_history(self, conversation_history: list) -> dict:
        """
        使用 MediSearchClient 获取医学建议。
        """
        conversation_id = str(uuid.uuid4())
        client = MediSearchClient(api_key=self.api_key)

        responses = client.send_user_message(conversation=conversation_history,
                                             conversation_id=conversation_id,
                                             should_stream_response=True,
                                             language="Chinese")
        last_text_event = None
        all_articles_events = []

        for response in responses:
            if response['event'] == 'llm_response':
                last_text_event = response['text']
            elif response['event'] == 'articles':
                all_articles_events.extend(response['articles'])

        return {
            "last_text_event": last_text_event,
            "articles": all_articles_events
        }

================
File: modules/flowchat.py
================
import asyncio
import requests
from playwright.async_api import async_playwright

class MermaidToImageUploader:
    def __init__(self):
        pass

    async def render_mermaid(self, mermaid_code):
        # HTML 模板，包含 Mermaid 的初始化和错误处理
        html_content = f"""
        <!DOCTYPE html>
        <html lang="zh">
        <head>
            <meta charset="UTF-8">
            <title>Mermaid Diagram</title>
            <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
            <script>
                mermaid.parseError = function(err, hash) {{
                    document.body.innerHTML = '<div id="error">' + err + '</div>';
                }};
                mermaid.initialize({{ startOnLoad: true }});
            </script>
        </head>
        <body>
            <div class="mermaid">
                {mermaid_code}
            </div>
        </body>
        </html>
        """

        async with async_playwright() as p:
            browser = await p.chromium.launch()
            page = await browser.new_page()
            await page.set_content(html_content)

            # 等待 Mermaid 图表渲染完成
            try:
                await page.wait_for_selector('.mermaid > svg', timeout=5000)
            except Exception as e:
                # 检查是否有错误信息
                error_element = await page.query_selector('#error')
                if error_element:
                    error_text = await error_element.text_content()
                    print("Mermaid 语法错误:", error_text)
                    await browser.close()
                    return None, error_text
                else:
                    print("渲染过程中发生未知错误。")
                    await browser.close()
                    return None, "渲染过程中发生未知错误。"

            # 选择 Mermaid 元素
            element = await page.query_selector('.mermaid')

            # 截图并获取二进制数据
            image_data = await element.screenshot(type='png')

            await browser.close()

        return image_data, None

    async def upload_image(self, image_data):
        # 上传图片并获取在线链接
        upload_url = "https://wx.jfzgai.com/api/wx/file/post-image-no-auth"

        files = {
            'file': ('mermaid_diagram.png', image_data, 'image/png')
        }
        headers = {
            'User-Agent': 'Apifox/1.0.0 (https://apifox.com)'
        }

        response = requests.post(upload_url, headers=headers, files=files)
        # 打印服务器的响应内容
        print("Upload response:", response.text)

        # 解析返回的 JSON，获取图片的 URL
        if response.status_code == 200:
            try:
                json_response = response.json()
                # 根据实际的返回结构，提取图片 URL
                image_url = json_response.get('data', {}).get('url')
                if image_url:
                    return image_url, None
                else:
                    return None, "未能从响应中获取图片 URL。"
            except ValueError:
                return None, "响应不是有效的 JSON 格式。"
        else:
            return None, f"图片上传失败，状态码：{response.status_code}"

    async def get_image_url(self, mermaid_code):
        image_data, error = await self.render_mermaid(mermaid_code)
        if image_data is None:
            return None, error
        else:
            image_url, upload_error = await self.upload_image(image_data)
            if image_url is None:
                return None, upload_error
            else:
                return image_url, None

================
File: modules/Markdown.py
================
'''
Date: 2024-10-14 15:31:49
LastEditors: yangyehan 1958944515@qq.com
LastEditTime: 2024-10-18 16:55:37
FilePath: /MediSearch/modules/Markdown.py
Description: 
'''
def render_markdown_image(url):
    """
    将给定的图片 URL 转换为适配屏幕大小的 Markdown 语法，并使图片可点击查看大图。
    """
    html_markdown = f'''
<div style="text-align: center;">
    <a href="{url}" target="_blank">
        <img src="{url}"  style="max-width: 100%; height: auto;">
    </a>
</div>
'''
    return html_markdown

def parse_mermaid_syntax(mermaid_str):
    """
    解析给定的 Mermaid 语法字符串，返回其内容。
    如果输入字符串包含以 ```mermaid 开头并以 ``` 结束的部分，则提取并解析。
    如果不包含，则返回原始字符串。
    """
    # 查找是否存在 ```mermaid 开头和 ``` 结尾的部分
    start_tag = "```mermaid"
    end_tag = "```"

    # 检查是否包含合法的 mermaid 语法代码块
    start_index = mermaid_str.find(start_tag)
    end_index = mermaid_str.rfind(end_tag)

    # 如果找到合法的 mermaid 代码块，提取中间内容
    if start_index != -1 and end_index != -1 and start_index < end_index:
        # 提取 mermaid 代码块部分
        mermaid_code = mermaid_str[start_index + len(start_tag):end_index].strip()
        return mermaid_code

    # 如果不是合法的 Mermaid 代码块，则返回原始内容
    return mermaid_str

================
File: modules/arxiv_search.py
================
'''
Date: 2024-10-13 17:37:45
LastEditors: yangyehan 1958944515@qq.com
LastEditTime: 2024-10-18 17:17:38
FilePath: /MediSearch/modules/arxiv_search.py
Description: 
'''
# modules/arxiv_search.py
import sys
sys.path.append('..')
import requests
from xml.etree import ElementTree as ET
from modules.llm_handler import LLMHandler
from modules.performance_tracker import track_performance

class ArxivSearch:
    def __init__(self):
        self.llm_handler = LLMHandler()

    @track_performance
    def fetch_keywords_from_conversation(self, conversation_history: list) -> list:
        """
        从对话历史中提取关键词。
        """
        advice_text = " ".join(conversation_history)
        prompt = f"""
        根据对话历史，提取一到两个关键词，用于后续的 arXiv 查询。
        返回格式仅包含关键词，每个关键词不超过两个英文单词。
        关键词应易于理解，不要使用复杂的医学词汇。
        格式如下：
        keyword1, keyword2
        以下为对话历史：
        {advice_text}
        """
        keywords = self.llm_handler.generate_response(prompt)
        return [kw.strip() for kw in keywords.strip().split(',')]

    @track_performance
    def search_arxiv_papers(self, keywords: list) -> str:
        """
        使用关键词搜索 arXiv 论文。
        """
        base_url = "http://export.arxiv.org/api/query?"
        search_query = '+AND+'.join([f'all:{keyword}' for keyword in keywords])
        query = f"search_query={search_query}&start=0&max_results=20"
        response = requests.get(base_url + query)
        if response.status_code == 200:
            return response.text
        else:
            return f"Error: {response.status_code}"

    @track_performance
    def parse_arxiv_response(self, xml_response: str) -> list:
        """
        解析 arXiv 的 XML 响应，提取论文信息。
        """
        root = ET.fromstring(xml_response)
        ns = {'atom': 'http://www.w3.org/2005/Atom'}

        articles = []
        for entry in root.findall('atom:entry', ns)[:10]:
            title = entry.find('atom:title', ns).text
            url = entry.find('atom:id', ns).text
            summary = entry.find('atom:summary', ns).text
            summary = summary.split('.')[0] + '.' if '.' in summary else summary
            keywords = [category.attrib['term'] for category in entry.findall('atom:category', ns)]
            articles.append({
                'title': title,
                'url': url,
                'keywords': keywords,
                'summary': summary
            })
        return articles

================
File: modules/summarizer.py
================
# modules/summarizer.py
import sys
sys.path.append('..')
from modules.llm_handler import LLMHandler
from modules.performance_tracker import track_performance
import html2text

class Summarizer:
    def __init__(self):
        self.llm_handler = LLMHandler()

    @track_performance
    def html_to_markdown(self, html_content: str) -> str:
        """
        将 HTML 内容转换为 Markdown 格式。
        """
        converter = html2text.HTML2Text()
        converter.ignore_links = True
        markdown_content = converter.handle(html_content)
        return markdown_content

    @track_performance
    def summarize_html_content(self, article_title: str, html_content: str) -> str:
        """
        总结 HTML 内容，生成简短摘要。
        """
        markdown_content = self.html_to_markdown(html_content)
        content = f"""
        请以简单易懂的方式解释以下 Markdown 内容中提到的治疗方法，特别是与“{article_title}”相关的信息。
        不要使用任何插件或工具，只需使用提供的 Markdown 内容。
        忽略文中的 HTML 标签、广告和不相关的链接，仅关注医疗信息。
        尝试在50字以内用中文概括，让没有医学背景的人也能理解。
        解释为什么采用这种治疗方式，并突出其关键好处。
        输出只需保留答案形式的文本内容，不包含任何 HTML 标签或 Markdown 的网页链接。
        如果出现 page not found 或其他错误情况，返回“网络出现异常，请稍后再试。”
        以下是 Markdown 内容：
        {markdown_content}
        """
        return self.llm_handler.generate_response(content)

    @track_performance
    def generate_outline(self, conversation_history: list) -> str:
        """
        根据对话历史生成结构化大纲。
        """
        advice_text = " ".join(conversation_history)
        prompt = f"""
        根据以下对话内容生成一个结构化大纲。
        不需要精确到具体细节。
        请尽量简明扼要，便于理解。使用 Markdown 格式。
        只需提供大纲内容，不需要额外说明。
        {advice_text}
        """
        return self.llm_handler.generate_response(prompt)

================
File: modules/llm_handler.py
================
# modules/llm_handler.py
import sys
sys.path.append('..')
from models.custom_llm import CustomLLM
from modules.performance_tracker import track_performance
from datetime import datetime

class Res:
    def __init__(self, response: str, outline: str, reference: str, arxiv_reference: str, user_question: list):
        self.response_text = response
        self.outline = outline
        self.reference = reference
        self.arxiv_reference = arxiv_reference
        self.user_question = user_question

class LLMHandler:
    def __init__(self):
        self.llm = CustomLLM()

    @track_performance
    def generate_response(self, prompt: str) -> str:
        """
        使用 LLM 生成响应。
        """
        try:
            return self.llm._call(prompt)
        except Exception as e:
            return f"生成响应失败：{e}"

    def SearchPrompt(self, response: Res) -> str:
        # 获取当前日期和时间
        current_time = datetime.now()
        formatted_time = current_time.strftime('%Y-%m-%d %H:%M:%S')

        prompt = f"""
        # 助手背景

        你是经方智谷学术搜索引擎，由安果科技有限公司训练的 AI 学术搜索助手。

        # 总体指令

        根据 INITIAL_QUERY 和提供的大纲，撰写准确、详细、全面的回应。
        附加上下文作为 Original Response 和具体问题后的参考。
        回答应基于提供的 "Search results"。

        你的回答必须详细、结构化。优先使用列表、表格和引用来组织内容。
        回答应精准、高质量，使用专业且公正的语气。

        你必须引用最相关的搜索结果。不要提及不相关的结果。
        引用格式：
        - 引用必须始终使用英文格式，无论答案使用何种语言。
        - 每个引用以 [citation:x] 开头，其中 x 是数字。
        - 在对应句子的末尾，用方括号包含引用编号，如 "冰比水轻。[citation:3]" 或 "北京是中国的首都。[citation:5]"
        - 引用和前面的单词之间不加空格，始终使用方括号。

        如果搜索结果为空或无用，请根据现有知识回答问题。

        格式要求：
        - 使用 markdown 格式化段落、列表、表格和引用。
        - 使用四级标题（####）分隔回答的部分，但不要以标题开始回答。
        - 列表使用单换行，段落之间使用双换行。
        - 使用 markdown 渲染搜索结果中给出的图像。
        - 不要写 URL 或链接。

        你必须为学术研究查询提供长而详细的答案。
        回答应格式化为科学写作，使用段落和章节，使用 markdown 和标题。

        # 大纲
        {response.outline}

        以下是搜索结果：
        # 原始响应：
        {response.response_text}

        # 详细参考
        {response.reference}
        # ArXiv 参考文献：
        {response.arxiv_reference}

        你的回答必须使用与用户问题相同的语言。如果用户问题是中文，回答也应是中文。

        今天的日期是 {formatted_time}，以下是 INITIAL_QUERY：
        {response.user_question}
        """
        return prompt

    def Mermaid_Graph_Prompt(self, response: Res) -> str:
        prompt = f"""
        你需要将输入的大纲转换为流程图或思维导图，必须使用 mermaid 语法输出！
        # 大纲：
        {response.outline}
        判断大纲更适合以思维导图还是流程图表示，并以 mermaid 语法输出，不要给出任何多余解释！
        只需输出 mermaid 语法，不能输出其他格式或多余语句！
        请严格按照以下格式输出：
        ```mermaid
        ```
        输出：
        """
        return prompt

================
File: modules/performance_tracker.py
================
'''
Date: 2024-10-13 16:54:05
LastEditors: yangyehan 1958944515@qq.com
LastEditTime: 2024-10-18 16:55:17
FilePath: /MediSearch/modules/performance_tracker.py
Description: 
'''
# modules/performance_tracker.py
import sys
sys.path.append('..')
import time
import asyncio
from functools import wraps

# 存储函数性能数据的字典
func_performance = {}

# 全局变量用于存储程序总时间
program_start_time = None
program_end_time = None

def track_performance(func):
    @wraps(func)
    async def async_wrapper(*args, **kwargs):
        start_time = time.time()
        result = await func(*args, **kwargs)
        end_time = time.time()
        elapsed_time = end_time - start_time

        # 更新性能数据
        if func.__name__ not in func_performance:
            func_performance[func.__name__] = {'calls': 0, 'total_time': 0}
        func_performance[func.__name__]['calls'] += 1
        func_performance[func.__name__]['total_time'] += elapsed_time

        return result

    @wraps(func)
    def sync_wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        elapsed_time = end_time - start_time

        # 更新性能数据
        if func.__name__ not in func_performance:
            func_performance[func.__name__] = {'calls': 0, 'total_time': 0}
        func_performance[func.__name__]['calls'] += 1
        func_performance[func.__name__]['total_time'] += elapsed_time

        return result

    if asyncio.iscoroutinefunction(func):
        return async_wrapper
    else:
        return sync_wrapper

def start_program_timer():
    global program_start_time
    program_start_time = time.time()

def end_program_timer():
    global program_end_time
    program_end_time = time.time()

def print_performance_data():
    print("{:<40} {:<10} {:<20} {:<20}".format('函数名', '调用次数', '总时间(秒)', '平均时间(秒)'))
    print("-" * 115)
    for func, data in func_performance.items():
        avg_time = data['total_time'] / data['calls']
        print("{:<40} {:<10} {:<20.2f} {:<20.2f}".format(func, data['calls'], data['total_time'], avg_time))

    if program_start_time and program_end_time:
        total_time = program_end_time - program_start_time
        print("\n{:<40} {:<10.2f}".format('程序总时间(秒)', total_time))
    else:
        print("\n程序总时间数据不完整。")
